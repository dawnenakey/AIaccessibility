{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('listings.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
    "                 'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
    "                 'host_url', 'host_name', 'host_location', 'host_about',\n",
    "                 'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
    "                 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', \n",
    "                 'host_listings_count', 'host_total_listings_count', 'host_verifications',\n",
    "                 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
    "                 'calendar_updated','first_review','last_review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.replace(r'\\$|,', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['price'] == 0 ,'price'] = np.nan\n",
    "df['price'] = df.groupby(['neighbourhood_group_cleansed','room_type'])['price'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bedrooms'] = df.groupby(['room_type'])['beds'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bathroom values\n",
    "df['bathrooms_cleaned'] = df['bathrooms_text'].str.replace(r'\\s.*', '', regex=True)\n",
    "df['bathrooms_cleaned'] = df['bathrooms_cleaned'].apply(lambda x: 0.5 if x in ('Half-bath', 'Shared','Private') else float(x)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'host_is_superhost': 'f', 'has_availability':'f','instant_bookable':'f', 'reviews_per_month': 0, 'number_of_reviews':0,\n",
    "          'number_of_reviews_ltm':0, 'number_of_reviews_l30d':0, 'bedrooms':1, 'bathrooms_cleaned': df['bathrooms_cleaned'].median()}\n",
    "df.fillna(value=values, inplace=True)\n",
    "\n",
    "df['host_is_superhost'] = df['host_is_superhost'].map({'t': 1, 'f': 0}).astype(int)\n",
    "df['has_availability'] = df['has_availability'].map({'t': 1, 'f': 0}).astype(int)\n",
    "df['instant_bookable'] = df['instant_bookable'].map({'t': 1, 'f': 0}).astype(int)\n",
    "\n",
    "df = df.astype(\n",
    "    {\n",
    "        'neighbourhood_group_cleansed': 'category',\n",
    "        'room_type' : 'category'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address skew in price feature with log transformation\n",
    "df['price_log'] = np.log(df['price'])\n",
    "\n",
    "# address skew in minimum nights with sqrt transformation\n",
    "df['minimum_nights_sqrt'] = np.sqrt(df['minimum_nights'])\n",
    "\n",
    "# address skew in with maximum nights log transformation\n",
    "df['maximum_nights_long'] = np.log(df['maximum_nights'])\n",
    "\n",
    "# address skew in minimum_minimum_nights with sqrt transformation\n",
    "df['minimum_minimum_nights_sqrt'] = np.sqrt(df['minimum_minimum_nights'])\n",
    "\n",
    "# address skew in minimum_maximum_nights with log transformation\n",
    "df['minimum_maximum_nights_log'] = np.log(df['minimum_maximum_nights'])\n",
    "\n",
    "# address skew in maximum_maximum_nights with log transformation\n",
    "df['maximum_maximum_nights_log'] = np.log(df['maximum_maximum_nights'])\n",
    "\n",
    "# address skew in maximum_nights_avg_ntm with log transformaiton\n",
    "df['maximum_nights_avg_ntm_log'] = np.log(df['maximum_nights_avg_ntm'])\n",
    "\n",
    "# address skew in number_of_reviews_ltm with sqrt transformation\n",
    "df['number_of_reviews_ltm_sqrt'] = np.sqrt(df['number_of_reviews_ltm'])\n",
    "\n",
    "# address skew in number_of_reviews_l30d with sqrt transformation\n",
    "df['number_of_reviews_l30d_sqrt'] = np.sqrt(df['number_of_reviews_l30d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find length of time for host\n",
    "df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "df['today'] = pd.to_datetime(date.today())\n",
    "df['host_length_years'] = (df['today'] - df['host_since']) / np.timedelta64(1, 'D')\n",
    "df['host_length_years'] = round((df['host_length_years'] *  0.0027379),2).astype(float)\n",
    "\n",
    "df.fillna(value={'host_length_years': df['host_length_years'].median()}, inplace=True)\n",
    "\n",
    "df.drop(columns=['bathrooms','bathrooms_text','today','host_since'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df,columns=['neighbourhood_group_cleansed'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['amenities'] = df_encoded['amenities'].str.replace('\"', '')\n",
    "df_encoded['amenities'] = df_encoded['amenities'].str.replace('[', '')\n",
    "df_encoded['amenities'] = df_encoded['amenities'].str.replace(']', '')\n",
    "df_encoded['amenities'] = df_encoded['amenities'].str.replace(r'\\\\u.*','', regex = True)\n",
    "df_encoded['amenities'] = df_encoded['amenities'].str.strip()\n",
    "df_encoded['free_parking_on_premises'] = df_encoded['amenities'].str.contains(r'Free parking on premises|Free driveway parking.*', case=False, regex=True)\n",
    "df_encoded['paid_parking_on_premises'] = df_encoded['amenities'].str.contains(r'PAID.*PARKING.*ON PREMISES|PAID PARKING GARAGE ON PREMISES|Paid parking lot on premises|Paid valet parking on premises', case=False, regex=True)\n",
    "df_encoded['parking_off_premises'] = df_encoded['amenities'].str.contains(r'.*STREET PARKING|.*PARKING OFF PREMISES|PAID PARKING LOT OFF PREMISES|PAID PARKING GARAGE OFF PREMISES', case=False, regex=True)\n",
    "df_encoded['washer'] = df_encoded['amenities'].str.contains(r'WASHER|FREE WASHER|PAID WASHER', case=False, regex=True)\n",
    "df_encoded['dryer'] = df_encoded['amenities'].str.contains(r'DRYER|FREE DRYER|PAID DRYER', case=False, regex=True)\n",
    "df_encoded['AC'] = df_encoded['amenities'].str.contains(r'Central air conditioning|AIR CONDITIONING|Window AC unit|AC - split type ductless system', case=False, regex=True)\n",
    "df_encoded['heating'] = df_encoded['amenities'].str.contains(r'HEATING|CENTRAL HEATING|Radiant heating|Heating - split type ductless system', case=False, regex=True)\n",
    "df_encoded['wifi'] = df_encoded['amenities'].str.contains(r'WIFI|.*WIFI', case=False, regex=True)\n",
    "df_encoded['TV'] = df_encoded['amenities'].str.contains(r'TV|TV\\s.*|.*HDTV.*', case=False, regex=True)\n",
    "df_encoded['self_check_in'] = df_encoded['amenities'].str.contains('Self check-in')\n",
    "df_encoded['gym'] = df_encoded['amenities'].str.contains(r'GYM|Shared gym in building|PRIVATE GYM IN BUILDING', case=False, regex=True)\n",
    "df_encoded['pets_allowed'] = df_encoded['amenities'].str.contains('Pets allowed')\n",
    "df_encoded['kitchen'] = df_encoded['amenities'].str.contains(r'KITCHEN|KITCHENETTE', case=False, regex=True)\n",
    "df_encoded['patio_balcony'] = df_encoded['amenities'].str.contains(r'.*PATIO OR BALCONY', case=False, regex=True)\n",
    "df_encoded['backyard'] = df_encoded['amenities'].str.contains(r'.*BACKYARD.*', case=False, regex=True)\n",
    "df_encoded['pool'] = df_encoded['amenities'].str.contains('Pool')\n",
    "df_encoded['luggage_dropoff_allowed'] = df_encoded['amenities'].str.contains('Luggage dropoff allowed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "corrs = df_encoded.corr(numeric_only=True)\n",
    "corrs.drop(columns=['latitude','longitude'],inplace=True)\n",
    "\n",
    "targetCor = corrs.drop('price_log')['price_log']\n",
    "\n",
    "targetCor.loc[targetCor.abs().sort_values(ascending= False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Airbnb_listings_cleaned.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
